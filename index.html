<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>360° Gyro Calibrator</title>
    <style>
        body { margin: 0; overflow: hidden; background: #000; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
        
        #ui { 
            position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); 
            text-align: center; color: white; z-index: 10; width: 80%; max-width: 400px;
            background: rgba(0, 0, 0, 0.8); padding: 30px; border-radius: 20px; border: 1px solid #444;
        }

        #videoUpload { margin: 20px 0; color: #ccc; }

        button { 
            padding: 15px 40px; font-size: 18px; font-weight: bold; cursor: pointer; 
            background: #007bff; color: white; border: none; border-radius: 50px;
            transition: all 0.3s ease; box-shadow: 0 4px 15px rgba(0,123,255,0.4);
        }

        button:disabled { background: #555; cursor: wait; box-shadow: none; }

        #instructions { font-size: 14px; color: #aaa; margin-top: 15px; line-height: 1.4; }
    </style>
</head>
<body>

    <div id="ui">
        <h1>360° VR Player</h1>
        <p>Select your .mp4 file to begin</p>
        <input type="file" id="videoUpload" accept="video/*"><br>
        <button id="startBtn">Start & Calibrate</button>
        <div id="instructions">
            After clicking, hold the phone perfectly still at eye level for 3 seconds to zero the sensors.
        </div>
    </div>

    <script type="importmap">
        { "imports": { "three": "https://unpkg.com/three@0.160.0/build/three.module.js" } }
    </script>

    <script type="module">
        import * as THREE from 'three';

        let scene, camera, renderer, video, texture;
        let isCalibrated = false;
        let calibrationData = { alpha: 0, beta: 0, gamma: 0 };
        let samples = { alpha: [], beta: [], gamma: [] };

        const ui = document.getElementById('ui');
        const startBtn = document.getElementById('startBtn');
        const fileInput = document.getElementById('videoUpload');

        function init() {
            // 1. Scene Setup
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 1, 1100);
            camera.target = new THREE.Vector3(0, 0, 0);

            // 2. Renderer Setup
            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            document.body.appendChild(renderer.domElement);

            // 3. Create the 360 Sphere
            const geometry = new THREE.SphereGeometry(500, 60, 40);
            geometry.scale(-1, 1, 1); // Flip sphere to see from inside

            video = document.createElement('video');
            video.loop = true;
            video.muted = false; 
            video.playsInline = true;

            texture = new THREE.VideoTexture(video);
            texture.colorSpace = THREE.SRGBColorSpace;
            
            const material = new THREE.MeshBasicMaterial({ map: texture });
            const sphere = new THREE.Mesh(geometry, material);
            scene.add(sphere);

            window.addEventListener('resize', onWindowResize);
            animate();
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
        }

        // Handle File Upload
        fileInput.onchange = (e) => {
            const file = e.target.files[0];
            if (file) {
                video.src = URL.createObjectURL(file);
                video.load();
            }
        };

        // Calibration logic
        function handleOrientation(event) {
            if (!isCalibrated) {
                // Collect sensor data for averaging
                samples.alpha.push(event.alpha || 0);
                samples.beta.push(event.beta || 0);
                samples.gamma.push(event.gamma || 0);
                return;
            }

            // Calculate relative movement (Current - Initial Offset)
            const alpha = THREE.MathUtils.degToRad(event.alpha - calibrationData.alpha);
            const beta = THREE.MathUtils.degToRad(event.beta - calibrationData.beta);
            const gamma = THREE.MathUtils.degToRad(event.gamma - calibrationData.gamma);

            // Apply rotation using mobile-friendly order
            camera.rotation.set(beta, alpha, -gamma, 'ZXY');
        }

        async function startSequence() {
            if (!video.src) { alert("Please select a video file first."); return; }

            // Permission check for iOS
            if (typeof DeviceOrientationEvent.requestPermission === 'function') {
                try {
                    const permission = await DeviceOrientationEvent.requestPermission();
                    if (permission !== 'granted') return;
                } catch (err) { console.error(err); }
            }

            window.addEventListener('deviceorientation', handleOrientation);

            // Start 3-second countdown
            startBtn.disabled = true;
            let count = 3;
            const timer = setInterval(() => {
                startBtn.innerText = `Calibrating: ${count}...`;
                count--;
                if (count < 0) {
                    clearInterval(timer);
                    finishCalibration();
                }
            }, 1000);
        }

        function finishCalibration() {
            const avg = arr => arr.length ? arr.reduce((a, b) => a + b, 0) / arr.length : 0;
            
            calibrationData.alpha = avg(samples.alpha);
            calibrationData.beta = avg(samples.beta);
            calibrationData.gamma = avg(samples.gamma);

            isCalibrated = true;
            ui.style.display = 'none';
            video.play();
            
            if (document.documentElement.requestFullscreen) {
                document.documentElement.requestFullscreen();
            }
        }

        startBtn.addEventListener('click', startSequence);
        init();
    </script>
</body>
</html>
